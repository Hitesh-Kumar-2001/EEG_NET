# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aUzfy3I-5dWYrpk9rwP-vn99nA3oSVSN
"""

from google.colab import drive
drive.mount("/content/drive")

import os
import numpy as np
import torch
import torch.nn as nn
from model import EEGNet_v2
from torch.autograd import Variable
# from EEG_VAE import vae,EEG_CNN_VAE,gen
from torch.utils.data import Dataset, DataLoader
import random
import time



path = "/content/drive/MyDrive/eeg"
gen_size = [1000]
models = "dc"

filenames = {
   "train":  ("train_data_numpy.npy","train_labels_numpy.npy"),
    "test":  ("test_data_numpy.npy","test_labels_numpy.npy"),
      "dc":  ("dc_gandata.npy","labels_dcgandata.npy"),
    "wgan":  ("w_gandata1000.npy","labels_wgandata1000.npy"),
     "vae":  ("vae_gandata1000.npy","labels_vaegandata1000.npy")

}

path2 = "/content/drive/MyDrive/model/vae_model_11"

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(device)
print(torch.cuda.is_available())
model = EEG_CNN_VAE()
model.load_state_dict(torch.load(path2))
model.eval()

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(device)
print(torch.cuda.is_available())
model = EEG_CNN_VAE()
model.load_state_dict(torch.load(path2))
model.eval()

"""helper function"""
def load(s,x,v):
    data = [np.load(os.path.join(path,filenames[s][0]))]
    data = np.concatenate(data)
    data = data.reshape(-1,1,22,1125)
    print(data.shape)
    label = [np.load(os.path.join(path,filenames[s][1]))]
    label = np.concatenate(label)
    label = label.reshape(-1)
    if v.shape[0]==0:
      v = data
    else :  
      v = np.concatenate((train_data , data))
    for i in range(label.shape[0]):
        x.append(prob[label[i]])
    return v,x
    
     
seed_n = np.random.randint(500)
"""variables"""
batch_size = 100
chans = 22
samples = 1125
lr = 0.01
epochs =  50 + 100
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

prob = [[1,0,0,0],
        [0,1,0,0],
        [0,0,1,0],
        [0,0,0,1],]
train_data = np.array([])
test_data = np.array([])
labels_train = []
labels_test = []
#################################################################################################
"""train data loading"""
print("loading train data....")

######### data generation ##############################


data,labels = gen([1000],model.to(device))#generating 1000 data samples

data = np.array(data["1000"]).reshape(-1,1,22,1125)
train_data = data#np.concatenate((train_data,data))
for i in range(len(labels["1000"])):
  # print(labels["4"][i])
  labels_train.append(prob[labels["1000"][i]])

train_data , labels_train = load("train",labels_train, train_data)# train data


# print("2@",np.array(labels_train).shape,train_data.shape)





###### loading test data ###############
print("loading test data....")
test_data,labels_test  = load("test",labels_test,test_data)


######### data to torch tensor #############################################33
train_data.astype(np.float32)
test_data.astype(np.float32)
labels_train = np.array(labels_train).astype(np.float32)
train_data = torch.from_numpy(train_data).float()
labels_train = torch.from_numpy(labels_train).float()
print("train:",train_data.shape,labels_train.shape)
print("test:",test_data.shape,len(labels_test))
dataset = torch.utils.data.TensorDataset(train_data, labels_train)
dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)
print("data loaded...")



################################################################################################
"""model"""
model = EEGNet_v2(4,Chans=chans, Samples=samples).to(device)
criterion = nn.BCELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=lr)


"""training"""
print("training.....")
for epoch in range(epochs):
    model.train()
    running_tr_loss = 0.0
    for i, data in enumerate(dataloader, 0):
        data, labels = data
        model.zero_grad()
        predictions = model(Variable(torch.tensor(data)).to(device))
        loss = criterion(torch.special.expit(predictions), torch.tensor(labels.to(device)))
        loss.backward()
        optimizer.step()
        running_tr_loss += loss.item()


    train_loss = running_tr_loss / len(train_data)
    print("Epoch [{}]: train loss [{}]".format(epoch, train_loss))
    
    
    

list1 = []
list2 = []
len(test_data)
"""testing"""
print("testing")
model.eval()
count = 0
with torch.set_grad_enabled(False):
        data = []
        labels = []
        model.zero_grad()
        for i in range(len(test_data)):
            x,y= test_data[i],labels_test[i]
            data.append(np.array(x))
            labels.append(np.array(y).astype(np.float32))
        predictions = model(Variable(torch.tensor(data).float()).to(device))
        labels = torch.tensor(labels).to(device)
        labels = torch.argmax(labels,dim=1).cpu().numpy()
        
        list2.append(labels)
        predictions = torch.argmax(predictions,dim=1).cpu().numpy()
        list1.append(predictions)

        for i in range(predictions.shape[0]):
            if predictions[i]==labels[i]:
                count+=1
        


print("accuracy", count/len(test_data))

