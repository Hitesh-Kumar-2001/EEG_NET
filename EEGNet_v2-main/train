import os
import numpy as np
import torch
import torch.nn as nn
# from Data_prep import data_process
from model import EEGNet_v2
from torch.autograd import Variable
from torch.utils.data import Dataset, DataLoader
import random
import time
# torch.special.expit as sigmoid

seed_n = np.random.randint(500)
"""variables"""
batch_size = 100
chans = 22
samples = 1125
lr = 0.000001
epochs = 150

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')


filenames = {
   "train":  ("train_data_numpy.npy","train_labels_numpy.npy"),
    "test":  ("test_data_numpy.npy","test_labels_numpy.npy"),
      "dc":  ("dc_gandata.npy","labels_dcgandata.npy"),
    "wgan":  ("w_gandata.npy","labels_wgandata.npy"),
     "vae":  ("vae_gandata.npy","labels_vaedata.npy")



"""loading data"""
print("loading data....")


prob = [[1,0,0,0],
        [0,1,0,0],
        [0,0,1,0],
        [0,0,0,1],]

train_data = np.array([])
test_data = np.array([])
labels_train = []
labels_test = []



#######  loading train data ############
data = [np.load(path+filenames['train'][0])]
data = np.concatenate(data)
label = [np.load(path+filenames['train'][1])]
label = np.concatenate(label)
train_data = data

for i in range(label.shape[0]):
  labels_train.append(prob[label[i]])


#####  loading dc_gan data ################
data = [np.load(path+filenames['dc'][0])]
data = np.concatenate(data)
data = data[:,:,np.newaxis,:,:]
label = [np.load(path+filenames['dc'][1])]
label = np.concatenate(label)
for i in range(4):
 train_data = np.concatenate((train_data , data[i]))
print("@",train_data.shape)

for c in range(4):
  for i in range(label.shape[1]):
    labels_train.append(prob[label[c][i]])

#####  loading w_gan data ################
data = [np.load(path+filenames['wgan'][0])]
data = np.concatenate(data)
data = data[:,:,np.newaxis,:,:]
label = [np.load(path+filenames['wgan'][1])]
label = np.concatenate(label)
for i in range(4):
 train_data = np.concatenate((train_data , data[i]))
print("@",train_data.shape)

for c in range(4):
  for i in range(label.shape[1]):
    labels_train.append(prob[label[c][i]])


#####  loading vae_gan data ################
data = [np.load(path+filenames['vae'][0])]
data = np.concatenate(data)
label = [np.load(path+filenames['vae'][1])]
label = np.concatenate(label)
train_data = np.concatenate((train_data , data))

for i in range(label.shape[0]):
  labels_train.append(prob[label[i]])

print("@",train_data.shape)

print(len(labels_train))
###### loading test data ###############
data = [np.load(path+filenames['test'][0])]
data = np.concatenate(data)
label = [np.load(path+filenames['test'][1])]
label = np.concatenate(label)
test_data = data
for i in range(label.shape[0]):
  labels_test.append(prob[label[i]])



import gc
gc.collect()




train_data.astype(np.float32)
labels_train = np.array(labels_train).astype(np.float32)
train_data = torch.from_numpy(train_data)
labels_train = torch.from_numpy(labels_train)
print(train_data.shape,labels_train.shape)
dataset = torch.utils.data.TensorDataset(train_data, labels_train)
dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)
print("data loaded...")

################################################################################################
"""model"""
model = EEGNet_v2(4,Chans=chans, Samples=samples).to(device)
criterion = nn.BCELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=lr)


"""training"""
print("training.....")
for epoch in range(epochs):
    model.train()
    running_tr_loss = 0.0
    for i, data in enumerate(dataloader, 0):

    # for batch in range(0,len(train_data),batch_size):
        data, labels = data
        model.zero_grad()
        #print(data,labels)
        # for i in range(batch_size):
            # x,y= train_data[batch+i]['data'] , train_data[batch+i]['labels']
            # data.append(np.array(x))
            # labels.append(np.array(y).astype(np.float32))
        predictions = model(Variable(torch.tensor(data)).to(device))
        loss = criterion(torch.special.expit(predictions), torch.tensor(labels.to(device)))
        loss.backward()
        optimizer.step()
        running_tr_loss += loss.item()


    train_loss = running_tr_loss / len(train_data)
    print("Epoch [{}]: train loss [{}]".format(epoch, train_loss))

list1 = []
list2 = []
len(test_data)
"""testing"""
print("testing")
model.eval()
count = 0
with torch.set_grad_enabled(False):
    # for batch in range(0,len(train_data),batch_size):
        data = []
        labels = []
        model.zero_grad()
        for i in range(len(test_data)):

            x,y= test_data[i],labels_train[i]
            data.append(np.array(x))
            labels.append(np.array(y).astype(np.float32))
        predictions = model(Variable(torch.tensor(data)).to(device))
        labels = torch.tensor(labels).to(device)
        labels = torch.argmax(labels,dim=1).cpu().numpy()
        list1.append(predictions)
        list2.append(labels)
        predictions = torch.argmax(predictions,dim=1).cpu().numpy()

        for i in range(predictions.shape[0]):
            if predictions[i]==labels[i]:
                count+=1


print("accuracy", count/len(test_data) )


